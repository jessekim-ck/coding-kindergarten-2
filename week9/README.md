# 9주차: 신경망의 학습과 오차역전파법

## 1. 신경망의 학습
딥러닝의 핵심은 모든 파라미터 값들을, 사람의 개입 없이 데이터만으로부터 학습한다는 것. 이 때, 모델에게 학습의 기준이 되는 '손실 함수'를 정의해야 한다.

## 2. 손실 함수 (Loss Function)
모델에게 각각의 **추론 결과가 정답과 '얼마나 가까운지'** 알려주면, 모델은 이를 기준으로 파라미터 값들을 조정한다!

우선 여기서는 k 개의 class를 구별하는 k-class classification 문제에 집중하기로 한다.

이 때 $y_k$ 는 k 번째 class에 대한 신경망의 출력값을, $t_k$ 는 역시 k 번째 class에 대한 정답 레이블을 의미. 아래와 같이 k-class를 나타내는 형식을 one-hot-encoding이라 부른다.

```python
# for the case of k=10 classification
y = [0.1, 0.3, 0.05, 0.0, 0.0, 0.05, 0.5, 0.0, 0.0, 0.0]
t = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
```

### 2.1. 평균 제곱 오차 (MSE, Mean Sqared Error)
각 class에 대한 정답값과 출력값의 차이의 제곱의 평균.

$$
E = \frac{1}{2} \sum_k{(y_k - t_k)^2}
$$

*실습: MSE 구현하기!*

### 2.2. 교차 엔트로피 오차 (CEE, Cross Entropy Error)
$t_k$ 가 1일 때에만 값이 0이 아니게 된다. 즉 정답 레이블에 대한 출력값이 전체 오차값을 결정하게 된다. 또 -log 값은 0에 가까울수록 무한히 커지고, 1에 가까울수록 0에 수렴한다. 가장 일반적으로 사용되는 오차.

$$
E = -\sum_k{t_k \log{y_k}}
$$

*실습: CEE 구현하기!*

### 2.3. 미니 배치 (Mini Batch)
딥러닝에서는 추론 및 학습 시, **몇 개의 데이터(e.g. 이미지)를 묶어 한 번에 추론**한다. 그 이유는...
- 한 번에 모든 데이터를 추론/학습하지 않는 이유는, 근본적으로는 컴퓨터의 메모리가 한정되어있기 때문. 컴퓨터는 10만 장의 이미지를 한 번에 연산할 수 없다!
- 한 번에 하나의 데이터만 추론/학습하지 않는 이유는, 비효율적이기 때문. GPU는 병렬 처리에 특화되어 있기 때문에, 128장의 이미지를 연산하는 것과 1장의 이미지를 연산하는 것의 속도 차이가 크지 않다!

따라서 학습할 때에도 당연히 몇 개의 데이터를 묶어서 추론하고 학습한다. 이 때 이 몇 개의 데이터 묶음을 batch라 부르고, '몇'개인지를 batch size라 부른다. 

하나의 배치에 대한 오차값은 다음과 같이 계산한다. 이 때, n은 N-size batch의 n번째 데이터를 의미한다. 즉 그냥 각 오차값들의 평균이다!

$$
L = \frac{1}{N}\sum_n^N{E_n}
$$

## 3. 학습
딥러닝 모델 학습의 근본적인 목표는, 학습하지 않은 임의의 데이터에 대한 오차값을 최소화하는 것이다. 하지만 학습하지 않은 임의의 데이터에 대해서는 학습을 진행할 수 없기 때문에, **학습 데이터에 대한 오차값을 최소화함**으로써 원하고자 하는 모델을 근사하게 된다.

### 3.1. 학습의 목표
즉 간단히 말하자면 학습 데이터에 대해 오차값을 최소화하는 것이 목표이다! 다시 말해 **$L = f(x, \theta)$ 를 최소화하는 $\theta$ 를 찾는 것이 목표**이다. 어디서 많이 본 형태인 것 같다. 여러가지 가정이 필요하긴 하지만, 다음을 만족하는 $\theta$를 찾으면 되는 것이다!

$$
\frac{\partial{E}}{\partial{\theta}} = 0
$$

### 3.2. 경사하강법(Gradient Descent Method)
하지만 위와 같은 최적해를 해석적으로 찾아내는 일이 불가능하다. 1) 데이터가 너무 많아서 한 번에 연산할 수가 없고, 2) 파라미터가 너무 많아서 - 현대의 딥러닝 모델들은 파라미터의 수가 조 단위로 넘어가고 있다 - 역시나 연산을 불가능할 정도로 복잡하게 만들기 때문이다.

이러한 상황에서 최적해를 근사하기 위해 고안된 방법이 바로 경사하강법이다. 간단히 말하자면, **매 데이터의 배치마다 기울기가 가장 가파른 방향으로 (오차를 가장 가파르게 감소시키는 방향으로) 파라미터들을 조금씩 업데이트하는 것!** 즉 식으로 나타내보자면...

$$
\theta_i = \theta_i - \eta \frac{\partial f}{\partial \theta_i}
$$

를 매 배치마다, 모든 파라미터에 대해서 진행해주는 것이다. 이 때 $\eta$ 를 learning rate(학습률)이라 부른다. 그러면 이론상 파라미터 값들은 오차값을 조금씩 감소시키는 방향으로 계속 학습될 것이다!!

딥러닝 학습 시에는 매번 배치를 랜덤하게 추출하게 되는데, 이러한 방법을 확률적 경사하강법(SGD - Stochastic Gradient Descent)라 부른다.

![Gradient Descent](https://www.researchgate.net/profile/Alexander-Amini/publication/325142728/figure/fig1/AS:766109435326465@1559666131320/Non-convex-optimization-We-utilize-stochastic-gradient-descent-to-find-a-local-optimum.jpg)

여러모로 경사하강법이 어쩔 수 없이 울며 겨자먹기로 선택하게 된 방법처럼 보이는데, 사실 이러한 요소들이 오히려 이점을 준다는 사실들이 여러 논문들을 통해 밝혀진다. 예를 들자면...
- 모든 데이터를 한 번에 보는 게 아니라, 매번 랜덤한 배치를 학습하기 때문에 학습이 안장점에 빠지지 않도록 도와준다고 한다.
- 학습한 데이터(e.g. 검은 종이에 쓴 숫자)에 대해서만 낮은 오차를 보여주고, 학습하지 않은 새로운 데이터(e.g. 흰 종이에 쓴 숫자)에 대해서는 높은 오차를 보여주는 over-fitting 현상이 딥러닝 모델의 흔한 어려움 중 하나인데, 이러한 over-fitting을 줄여주는 효과가 있다고 한다.
- ...

### 3.3. 학습 알고리즘
정리해보자면, 딥러닝 모델은 다음과 같은 과정을 통해 데이터로부터 파라미터 값을 학습해낸다.
- 1단계: 학습 데이터로부터 N-size batch를 랜덤으로 가져온다.
- 2단계: 위 batch의 추론값을 신경망 모델을 통해 계산한다.
- 3단계: 위 추론값을 학습 데이터의 정답값과 비교하여 손실 함수를 계산한다.
- 4단계: 계산된 손실 함수를 각 파라미터에 대해 미분한다.
- 5단계: 미분값을 이용하여 SGD 알고리즘을 통해 모든 파라미터의 값을 조정한다.
- 6단계: 1~5단계를 계속해서 반복한다.

### 3.4. 학습 데이터, 테스트 데이터, 오버피팅
![Over-fitting](https://i.ytimg.com/vi/3NeRWVul5E0/maxresdefault.jpg)

위에서 오버피팅(over-fitting) 문제를 소개한 바 있다. 오버피팅은 딥러닝 프로젝트 진행 시 가장 많이 신경써야 할 부분 중 하나인데, 바로 학습 데이터에 대해서는 준수한 성능을 보여주지만, 학습되지 않은 데이터에 대해서는 전혀 준수하지 않는 성능을 보여주는 현상이다.

딥러닝 모델은 학습하기 쉬운 것들만 먼저 골라서 학습하려는 경향이 있다. 예를 들어 고양이와 강아지를 구분하는 딥러닝 모델을 학습시키고자 했는데, 공교롭게도 고양이 이미지는 모두 배경이 검정색이었고, 강아지 이미지는 모두 배경이 노랑색이었다고 해보자. 그러면 모델은 고양이와 강아지를 구분하는 것이 아니라 검정 배경과 노랑 배경을 구분하는 것을 먼저 학습하게 되고, 검정 배경의 강아지 이미지를 입력받았을 때, 고양이라고 추론하게 되는 것이다!

이와 같은 현상을 사전에 방지하기 위해 학습 데이터와 테스트 데이터를 나눈다. 학습 데이터로만 모델을 학습시키고, 학습되지 않은 데이터에 대해서도 준수한 데이터를 내는지 확인하기 위해, 테스트 데이터에 대한 성능을 계속해서 확인하는 것.

경우에 따라서는 train set, validation set, test set으로 나누는 경우도 있다. train set은 학습을 위해, validation set은 여러 모델의 성능을 비교하기 위해, test set은 최종 성능 검증을 위해 나눠놓는 것. 통상적으로 데이터셋의 비율은 8:1:1 혹은 9:1 정도로 나눈다.

오버피팅을 방지하는 여러 기법에 대해서는 나중에 또 다루기로!

## 4. 오차역전파법 (Error Back Propagation)
![Back propagation](https://i.ytimg.com/vi/Ilg3gGewQ5U/maxresdefault.jpg)

SGD를 통해 모델을 학습하기 위해서는, 오차값의 모든 파라미터에 대한 편미분값을 구해야 한다. 이를 위해 파라미터 수만큼 오차값을 계산하는 것은 말도 안 되게 비효율적인 일이 될 것이다! (상술했듯 현대 딥러닝 모델의 파라미터 수는 1조 개가 넘는 경우도 있다...!)

이러한 상황에서 **단 한 번의 신경망 연산으로 모든 파라미터에 대한 편미분값을 효율적으로 구해내는 방법이 바로 오차역전파법**이다. 신경망 계산을 마친 후 계산을 거꾸로 거슬러올라가며 편미분값을 구하기 때문에 back propagation이라 부른다. 반대로 추론값 계산은 forward propagation이라고도 부른다. (신경망 구현체의 forward 함수를 기억해보자ㅎㅎ)

### 4.1. 연쇄법칙
미분의 그 연쇄법칙이 맞다! **오차역전파법의 핵심은 바로 연쇄법칙**이다.

$$
f(g(x))' = f'(g(x))g'(x)
$$

딥러닝 모델은 각 layer 계산들의 합성함수이다. 이에 입각하여 연쇄법칙을 적용해보자. 이 때 $l_k$ layer의 출력값을 $a_k$ 라고 하자.

$$
y = a_3 = l_3(l_2(l_2(x, \theta_1), \theta_2), \theta_3)
\\ \ \\
\frac{\partial{y}}{\partial{a_3}} = 
\frac{\partial{a_3}}{\partial{a_3}} = 
1
\\ \ \\
\frac{\partial{y}}{\partial{a_2}} = 
\frac{\partial{a_3}}{\partial{a_3}}
\frac{\partial{a_3}}{\partial{a_2}}
= \frac{\partial{y}}{\partial{a_3}}
\frac{\partial{a_3}}{\partial{a_2}}
\\ \ \\
\frac{\partial{y}}{\partial{a_1}} = 
\frac{\partial{a_3}}{\partial{a_3}}
\frac{\partial{a_3}}{\partial{a_2}}
\frac{\partial{a_2}}{\partial{a_1}} = 
\frac{\partial{y}}{\partial{a_2}}
\frac{\partial{a_2}}{\partial{a_1}}
$$

여기서 layer k의 y에 대한 미분값은, layer k+1의 y에 대한 미분값($\partial{y}/{\partial{}a_{k+1}}$)에 layer k의 출력에 대한 입력값의 미분값($\partial{a_{k+1}}/\partial{a_k}$)을 곱한 것임을 알 수 있다.

즉 *마지막 layer부터 순차적으로 미분을 계산하고, 이를 앞 layer에 전달하고, 전달받은 미분값에 해당 layer의 미분값을 계산하여 곱하고, 이플 앞 layer에 전달하고...* 를 반복함으로써 모든 layer의 y에 대한 미분값을 구할 수 있게 된다!

### 4.2. 계산 그래프
이를 계산 그래프를 이용하여 더 알기 쉽게 표현해볼 수 있다.

### 4.3. 미분 계산
#### 4.3.1. Affine layer의 미분
$
f(x) = xW + b
\\ \ \\
\frac{\partial{f(x)}}{\partial{x}} = W^T
\\ \ \\
\frac{\partial{f(x)}}{\partial{W}} = x^T
\\ \ \\
\frac{\partial{f(x)}}{\partial{b}} = 1
$

#### 4.3.3. ReLU 미분
$
f(x) = \begin{cases}
x \ (x > 0) \\
0 \ (else)
\end{cases}
\\ \ \\
\frac{\partial{f(x)}}{\partial{x}} = \begin{cases}
1 \ (x > 0) \\
0 \ (else)
\end{cases}
$

#### 4.3.4. Sigmoid 미분
$
f(x) = \frac{1}{1 + \exp{(-x)}}
\\ \ \\
\frac{\partial{f(x)}}{\partial{x}} = f(x)(1 - f(x))
$

#### 4.3.5. Softmax w/ Cross Entropy 미분
편의상 Cross Entropy Loss 와 함께 미분한다. (이 때 t는 정답값)
$
f(x) = \text{CrossEntropy}{(\text{Softmax}{(x)})}
\\ \ \\
\frac{\partial{f(x)}}{\partial{x}} = f(x) - t
$

## 4.4. 구현하기
- 역전파 시 계산해야 할 부분은 두 가지입니다.
    - 입력값에 대한 미분값. 뒷 레이어에서 역전파된 값(`d_out`)에, 출력값을 입력값으로 미분한 값을 곱합니다.
    - 파라미터에 대한 미분값. 뒷 레이어에서 역전파된 값(`d_out`)에, 출력값을 파라미터로 미분한 값을 곱합니다.
- 팁: 역전파 계산에 필요한 값들은 순전파 계산 때 미리 저장해둡니다.

*실습: 신경망 구현하기!*

---
*E.O.D.*